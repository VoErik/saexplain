program: main.py
method: random
metric:
  name: losses/mse_loss
  goal: minimize

parameters:
  d_in:
    value: 768
  total_training_samples:
    value: 200_000_000
  autocast:
    value: true

  architecture:
    value: "topk"

  k:
    values: [20, 40, 80, 120, 160, 200] 
  
  aux_loss_coefficient:
    distribution: log_uniform_values
    min: 0.1
    max: 10.0
    
  rescale_acts_by_decoder_norm:
    values: [true, false]

  d_sae:
    values: [1536, 3072, 6144, 12288]
  
  lr:
    values: [1e-4, 3e-4, 5e-4]
    
  lr_scheduler_name:
    values: ["constant", "cosineannealing", "cosineannealingwarmrestarts"]

  lr_warm_up_steps:
    values: [1000, 5000]
    
  train_batch_size_samples:
    values: [2048, 4096]

  dead_feature_window:
    values: [2000, 5000] 

  datasets:
    value: ["fitzpatrick", "ham", "midas", "scin"]
  data_root:
    value: "../../data"
  model_path:
    value: "./ckpts/clip/openai-clip-vit-base-patch16-['ham', 'fitzpatrick', 'scin', 'midas']-best_model"
  cache_dir:
    value: "./cache"
  cls_only:
    value: false
  layer_index:
    value: -1
    
  log_to_wandb:
    value: true
  wandb_project:
    value: "sae_clip_patches_sweep"