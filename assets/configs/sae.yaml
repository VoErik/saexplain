mode: "sae"
# TRAINER CONFIG PARAMS
total_training_samples: 200_000_000
device: "cuda"
autocast: true
lr: 0.0001
lr_end: 0.00003
lr_scheduler_name: "cosineannealing"
lr_warm_up_steps: 1000
adam_beta1: 0.9
adam_beta2: 0.999
lr_decay_steps: 7500
n_restart_cycles: 1
train_batch_size_samples: 8192
dead_feature_window: 2000
feature_sampling_window: 5000
# Note: The 'logger: LoggingConfig' field is represented
# by the top-level 'logger:' block below.
eval_metric_mode: "min"
eval_metric_to_track: "losses/eval_loss"
model_save_path: "./ckpts/sae/"

# EMBEDDING CACHE CONFIG PARAMS
datasets:
  - "cub"
data_root: "../../data"
num_classes: 200
model_architecture: "dinov3"
model_name: null
model_checkpoint: "./ckpts/dinov3/dinov3-vit_base_patch16_dinov3.lvd1689m-cub.safetensors"
cache_dir: "./cache"
cls_only: false
extraction_batch_size: 64
layer_name:
  - "blocks.10"

# EVALUATOR CONFIG PARAMS
# (No default fields in the class for this section)
eval_batch_size: 1024
num_workers: 4
run_expensive_metrics: false

# SAE CONFIG PARAMS
## Basic configuration
d_in: 768
d_sae: 6144
device: "cuda"
dtype: "float32"
apply_b_dec_to_input: true
decoder_init_norm: 0.1
normalize_activations: "layer_norm"
architecture: "relu"
apply_sbp: false
ema_beta: 0.99
sbp_lambda: 20.0
sbp_alpha: 0.8
sbp_threshold: 0.0001
sbp_method: "alpha_mixing"

## relu
l1_coefficient: 2.545850855591968
lp_norm: 1.0
l1_warm_up_steps: 1000

## topk
k: 20
rescale_acts_by_decoder_norm: false
aux_loss_coefficient: 0.5132525619128137

## batchtopk
topk_threshold_lr: 0.01

## matryoshka
matryoshka_widths: [1000, 2000, 5000]

## jumprelu
jumprelu_init_threshold: 0.1
jumprelu_bandwidth: 0.1
jumprelu_sparsity_loss_mode: "step"
l0_coefficient: 1.0
l0_warm_up_steps: 0
pre_act_loss_coefficient: null
jumprelu_tanh_scale: 2.0

# LOGGING CONFIG PARAMS
log_to_wandb: true
log_model_artifacts_to_wandb: false
log_activations_store_to_wandb: false
log_optimizer_state_to_wandb: false
wandb_project: "sae_training"
wandb_id: null
run_name: "sbp_sae"
wandb_entity: "voerik"
wandb_log_frequency: 10
eval_every_n_wandb_logs: 500