model_type: clip  
pretrained_encoder_path: openai/clip-vit-large-patch14
dataset_name: midas
data_root: ../../data/
batch_size: 64
label_key: label
num_classes: 114
subgroup_columns: [fp_scale, fp_centaur]
k_values: [3, 5, 10, 20]
learning_rate: 0.001
num_epochs: 20
num_workers: 16